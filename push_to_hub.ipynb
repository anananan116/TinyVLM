{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.llama import get_model_and_tokenizer\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "model_args = {}\n",
    "with open(\"configs/Specialtokens/default.json\") as f:\n",
    "    special_token_map = json.load(f)\n",
    "model_args[\"pretrained_model\"] = \"results/checkpoint-5000\"\n",
    "additional_tokens_dict = {x['type']: x['token'] for x in special_token_map['added_tokens']}\n",
    "model, tokenizer, _ = get_model_and_tokenizer(model_args, additional_tokens_dict, load_vision_model=True)\n",
    "model = model.to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"test.png\")\n",
    "prompt = \"Here's an image:<IMGPLH>Describe this image.\"\n",
    "model = model.to(torch.float16)\n",
    "inputs = model.prepare_input_ids_for_generation([prompt], [image], tokenizer)\n",
    "output = model.generate(input_ids=inputs['input_ids'].to(\"cuda\"), attention_mask=inputs['attention_mask'].to(\"cuda\"), encoded_image = inputs[\"encoded_image\"], max_new_tokens = 128, do_sample=False)\n",
    "tokenizer.batch_decode(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub(\"anananan116/TinyVLM\")\n",
    "tokenizer.push_to_hub(\"anananan116/TinyVLM\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
