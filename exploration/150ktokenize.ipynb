{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from jinja2.ext import Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image</th>\n",
       "      <th>conversations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33471</td>\n",
       "      <td>000000033471.jpg</td>\n",
       "      <td>[{'from': 'human', 'value': '&lt;image&gt;\n",
       "What are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52846</td>\n",
       "      <td>000000052846.jpg</td>\n",
       "      <td>[{'from': 'human', 'value': 'Where is the cat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>334872</td>\n",
       "      <td>000000334872.jpg</td>\n",
       "      <td>[{'from': 'human', 'value': '&lt;image&gt;\n",
       "Are the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>319154</td>\n",
       "      <td>000000319154.jpg</td>\n",
       "      <td>[{'from': 'human', 'value': '&lt;image&gt;\n",
       "What colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>398214</td>\n",
       "      <td>000000398214.jpg</td>\n",
       "      <td>[{'from': 'human', 'value': 'What type of sign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157707</th>\n",
       "      <td>257414</td>\n",
       "      <td>000000257414.jpg</td>\n",
       "      <td>[{'from': 'human', 'value': '&lt;image&gt;\n",
       "What coul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157708</th>\n",
       "      <td>171272</td>\n",
       "      <td>000000171272.jpg</td>\n",
       "      <td>[{'from': 'human', 'value': 'What are the adva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157709</th>\n",
       "      <td>101038</td>\n",
       "      <td>000000101038.jpg</td>\n",
       "      <td>[{'from': 'human', 'value': 'What precautions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157710</th>\n",
       "      <td>124934</td>\n",
       "      <td>000000124934.jpg</td>\n",
       "      <td>[{'from': 'human', 'value': '&lt;image&gt;\n",
       "What risk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157711</th>\n",
       "      <td>163917</td>\n",
       "      <td>000000163917.jpg</td>\n",
       "      <td>[{'from': 'human', 'value': 'How could someone...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157712 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id             image  \\\n",
       "0        33471  000000033471.jpg   \n",
       "1        52846  000000052846.jpg   \n",
       "2       334872  000000334872.jpg   \n",
       "3       319154  000000319154.jpg   \n",
       "4       398214  000000398214.jpg   \n",
       "...        ...               ...   \n",
       "157707  257414  000000257414.jpg   \n",
       "157708  171272  000000171272.jpg   \n",
       "157709  101038  000000101038.jpg   \n",
       "157710  124934  000000124934.jpg   \n",
       "157711  163917  000000163917.jpg   \n",
       "\n",
       "                                            conversations  \n",
       "0       [{'from': 'human', 'value': '<image>\n",
       "What are ...  \n",
       "1       [{'from': 'human', 'value': 'Where is the cat ...  \n",
       "2       [{'from': 'human', 'value': '<image>\n",
       "Are the p...  \n",
       "3       [{'from': 'human', 'value': '<image>\n",
       "What colo...  \n",
       "4       [{'from': 'human', 'value': 'What type of sign...  \n",
       "...                                                   ...  \n",
       "157707  [{'from': 'human', 'value': '<image>\n",
       "What coul...  \n",
       "157708  [{'from': 'human', 'value': 'What are the adva...  \n",
       "157709  [{'from': 'human', 'value': 'What precautions ...  \n",
       "157710  [{'from': 'human', 'value': '<image>\n",
       "What risk...  \n",
       "157711  [{'from': 'human', 'value': 'How could someone...  \n",
       "\n",
       "[157712 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('llava_instruct_150k.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"anananan116/TinyVLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"You are a powerful visual assistant.\"\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": \"a\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"b\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a powerful visual assistant.'},\n",
       " {'from': 'human',\n",
       "  'value': '<image>\\nWhat are the colors of the bus in the image?'},\n",
       " {'from': 'gpt', 'value': 'The bus in the image is white and red.'},\n",
       " {'from': 'human',\n",
       "  'value': 'What feature can be seen on the back of the bus?'},\n",
       " {'from': 'gpt', 'value': 'The back of the bus features an advertisement.'},\n",
       " {'from': 'human',\n",
       "  'value': 'Is the bus driving down the street or pulled off to the side?'},\n",
       " {'from': 'gpt',\n",
       "  'value': 'The bus is driving down the street, which is crowded with people and other vehicles.'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1=df.iloc[0]['conversations']\n",
    "c1 = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}] + c1\n",
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Extension' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer\u001b[39m.\u001b[39;49mapply_chat_template(conversation, tokenize\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1811\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.apply_chat_template\u001b[0;34m(self, conversation, tools, documents, chat_template, add_generation_prompt, continue_final_message, tokenize, padding, truncation, max_length, return_tensors, return_dict, return_assistant_tokens_mask, tokenizer_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1806\u001b[0m     logger\u001b[39m.\u001b[39mwarning_once(\n\u001b[1;32m   1807\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mreturn_assistant_tokens_mask==True but chat template does not contain `\u001b[39m\u001b[39m{\u001b[39m\u001b[39m% g\u001b[39;00m\u001b[39meneration \u001b[39m\u001b[39m%\u001b[39m\u001b[39m}` keyword.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1808\u001b[0m     )\n\u001b[1;32m   1810\u001b[0m \u001b[39m# Compilation function uses a cache to avoid recompiling the same template\u001b[39;00m\n\u001b[0;32m-> 1811\u001b[0m compiled_template \u001b[39m=\u001b[39m _compile_jinja_template(chat_template)\n\u001b[1;32m   1813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(conversation, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)) \u001b[39mand\u001b[39;00m (\n\u001b[1;32m   1814\u001b[0m     \u001b[39misinstance\u001b[39m(conversation[\u001b[39m0\u001b[39m], (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)) \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(conversation[\u001b[39m0\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1815\u001b[0m ):\n\u001b[1;32m   1816\u001b[0m     conversations \u001b[39m=\u001b[39m conversation\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/utils/chat_template_utils.py:364\u001b[0m, in \u001b[0;36m_compile_jinja_template\u001b[0;34m(chat_template)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39m@lru_cache\u001b[39m\n\u001b[1;32m    363\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_compile_jinja_template\u001b[39m(chat_template):\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mclass\u001b[39;00m \u001b[39mAssistantTracker\u001b[39;00m(Extension):\n\u001b[1;32m    365\u001b[0m         \u001b[39m# This extension is used to track the indices of assistant-generated tokens in the rendered chat\u001b[39;00m\n\u001b[1;32m    366\u001b[0m         tags \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mgeneration\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m    368\u001b[0m         \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, environment: ImmutableSandboxedEnvironment):\n\u001b[1;32m    369\u001b[0m             \u001b[39m# The class is only initiated by jinja.\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Extension' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer.apply_chat_template(conversation, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
